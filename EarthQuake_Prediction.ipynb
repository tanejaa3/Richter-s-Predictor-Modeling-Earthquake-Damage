{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification-Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv(r'C:\\Users\\AnkushTaneja\\Downloads\\ML_Projects\\EarthQuake_Predictions\\Data\\train_values.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\AnkushTaneja\\Downloads\\ML_Projects\\EarthQuake_Predictions\\Data\\test_values.csv')\n",
    "train_labels = pd.read_csv(r'C:\\Users\\AnkushTaneja\\Downloads\\ML_Projects\\EarthQuake_Predictions\\Data\\train_labels.csv')\n",
    "train_data = pd.merge(train_values,train_labels,how='inner',on=['building_id'])\n",
    "df = pd.concat([train_data,test],axis=0,sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['damage_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent and Independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_id = df['building_id']\n",
    "damage_grade = df['damage_grade']\n",
    "\n",
    "df = df.drop(columns=['building_id','damage_grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "features = ['land_surface_condition', 'foundation_type', 'roof_type','ground_floor_type', \n",
    "            'other_floor_type', 'position','plan_configuration','legal_ownership_status']\n",
    "\n",
    "for feature in features:\n",
    "    df[feature] = le.fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['height_percentage'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Relation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = df.columns\n",
    "\n",
    "# mask = np.zeros_like(df[features].corr(), dtype=np.bool) \n",
    "# mask[np.triu_indices_from(mask)] = True \n",
    "\n",
    "# f, ax = plt.subplots(figsize=(16, 12))\n",
    "# plt.title('Pearson Correlation Matrix',fontsize=25)\n",
    "\n",
    "# sns.heatmap(df[features].corr(),linewidths=0.25,vmax=0.7,square=True,cmap=\"BuGn\", #\"BuGn_r\" to reverse \n",
    "#             linecolor='w',annot=True,annot_kws={\"size\":8},mask=mask,cbar_kws={\"shrink\": .9});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df))\n",
    "df_scaled.columns = df.columns\n",
    "df_scaled.index = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining labels back to main-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['damage_grade'] = damage_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_scaled.iloc[:260601]\n",
    "test = df_scaled.iloc[260601:]\n",
    "test = test.drop(columns=['damage_grade'])\n",
    "\n",
    "train['damage_grade']  = train['damage_grade'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Train further to make train | test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['damage_grade'])\n",
    "Y = train['damage_grade']\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(X,Y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr = lr.fit(xtrain,ytrain)\n",
    "pred_lr = lr.predict(xtest)\n",
    "\n",
    "f1_score(ytest,pred_lr,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(random_state=0,kernel='linear')\n",
    "svm_linear = svm_linear.fit(xtrain,ytrain)\n",
    "pred_svm_linear = svm_linear.predict(xtest)\n",
    "\n",
    "f1_score(ytest,pred_svm_linear,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(random_state=0)\n",
    "svm_rbf = svm_rbf.fit(xtrain,ytrain)\n",
    "pred_svm_rbf = svm_rbf.predict(xtest)\n",
    "\n",
    "f1_score(ytest,pred_svm_rbf,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt = dt.fit(xtrain,ytrain)\n",
    "pred_dt = dt.predict(xtest)\n",
    "\n",
    "f1_score(ytest,pred_dt,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf = rf.fit(xtrain,ytrain)\n",
    "pred_rf = rf.predict(xtest)\n",
    "\n",
    "f1_score(ytest,pred_rf,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=0)\n",
    "xgb = xgb.fit(xtrain,ytrain)\n",
    "pred_xgb = xgb.predict(xtest)\n",
    "\n",
    "f1_score(ytest,pred_xgb,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light - GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(random_state=0,n_estimators=300,learning_rate=0.50)\n",
    "lgb = lgb.fit(xtrain,ytrain)\n",
    "pred_lgb = lgb.predict(xtest)\n",
    "\n",
    "f1_score(ytest,pred_lgb,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cat-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost = CatBoostClassifier(random_state=0,n_estimators=200,learning_rate=0.50)\n",
    "cat_boost = cat_boost.fit(xtrain,ytrain)\n",
    "pred_cat_boost = cat_boost.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(ytest,pred_cat_boost,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sample = test\n",
    "predictions = lgb.predict(out_of_sample)\n",
    "df_predicted = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted['damage_grade'] = predictions\n",
    "df_predicted['building_id'] = building_id.iloc[260601:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = df_predicted[['building_id','damage_grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv(r'C:\\Users\\AnkushTaneja\\Downloads\\ML_Projects\\EarthQuake_Predictions\\Data\\Ankush_Submission.csv',\n",
    "                   index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
